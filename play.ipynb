{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "from torch.nn.modules.utils import _pair\n",
    "from collections import namedtuple\n",
    "\n",
    "\n",
    "class SelfAttentionConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size,\n",
    "                 stride=1, padding=0, groups=32, bias=True):\n",
    "        print('in_channels, out_channels, kernel_size, stride, padding, groups')\n",
    "        print(in_channels, out_channels, kernel_size, stride, padding, groups)\n",
    "        super(SelfAttentionConv2d, self).__init__()\n",
    "        if in_channels % groups != 0:\n",
    "            raise ValueError('in_channels must be divisible by groups')\n",
    "        if out_channels % groups != 0:\n",
    "            raise ValueError('out_channels must be divisible by groups')\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = _pair(kernel_size)\n",
    "        self.stride = _pair(stride)\n",
    "        self.padding = _pair(padding)\n",
    "        self.groups = groups  # multi-head count\n",
    "        self.weight = namedtuple('fakeweight', ['shape'])([self.out_channels, self.in_channels])\n",
    "\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.Tensor(1, out_channels, 1, 1))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        # relative position offsets are shared between multi-heads\n",
    "        self.rel_size = (out_channels) // 2\n",
    "        self.relative_x = nn.Parameter(torch.Tensor(\n",
    "            self.rel_size, self.kernel_size[1]))\n",
    "        self.relative_y = nn.Parameter(torch.Tensor(\n",
    "            (out_channels) - self.rel_size, self.kernel_size[0]))\n",
    "\n",
    "        self.weight_query = nn.Conv2d(self.in_channels, self.out_channels,\n",
    "                                      1, groups=self.groups, bias=False)\n",
    "        self.weight_key = nn.Conv2d(self.in_channels, self.out_channels,\n",
    "                                    1, groups=self.groups, bias=False)\n",
    "        self.weight_value = nn.Conv2d(self.in_channels, self.out_channels,\n",
    "                                      1, groups=self.groups, bias=False)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=3)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        init.kaiming_normal_(self.weight_query.weight, mode='fan_out', nonlinearity='relu')\n",
    "        init.kaiming_normal_(self.weight_key.weight, mode='fan_out', nonlinearity='relu')\n",
    "        init.kaiming_normal_(self.weight_value.weight, mode='fan_out', nonlinearity='relu')\n",
    "\n",
    "        if self.bias is not None:\n",
    "            bound = 1 / math.sqrt(self.out_channels)\n",
    "            init.uniform_(self.bias, -bound, bound)\n",
    "\n",
    "        init.normal_(self.relative_x, 0, 1)\n",
    "        init.normal_(self.relative_y, 0, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.size()\n",
    "        kh, kw = self.kernel_size\n",
    "        ph, pw = h + self.padding[0] * 2, w + self.padding[1] * 2\n",
    "\n",
    "        fh = (ph - kh) // self.stride[0] + 1\n",
    "        fw = (pw - kw) // self.stride[1] + 1\n",
    "\n",
    "        px, py = self.padding\n",
    "        x = F.pad(x, (py, py, px, px))\n",
    "\n",
    "        vq = self.weight_query(x)\n",
    "        vk = self.weight_key(x)\n",
    "        vv = self.weight_value(x)  # b, fc, ph, pw\n",
    "\n",
    "        # b, fc, fh, fw\n",
    "        win_q = vq[:, :, (kh - 1) // 2:ph - (kh // 2):self.stride[0],\n",
    "                   (kw - 1) // 2:pw - (kw // 2):self.stride[1]]\n",
    "\n",
    "        win_q_b = win_q.view(b, -1, fh, fw)  # b, g, fc/g, fh, fw\n",
    "\n",
    "        # (b, g, x, fh, fw), (b, g, y, fh, fw)\n",
    "        win_q_x, win_q_y = win_q_b.split(self.rel_size, dim=1)\n",
    "        win_q_x = torch.einsum('bxhw,xk->bhwk', (win_q_x, self.relative_x))  # b, fh, fw, kw\n",
    "        win_q_y = torch.einsum('byhw,yk->bhwk', (win_q_y, self.relative_y))  # b, fh, fw, kh\n",
    "\n",
    "        win_k = vk.unfold(2, kh, self.stride[0]).unfold(\n",
    "            3, kw, self.stride[1])  # b, fc, fh, fw, kh, kw\n",
    "\n",
    "        vx = (win_q.unsqueeze(4).unsqueeze(4) * win_k).sum(dim=1)  # b, fh, fw, kh, kw\n",
    "        vx = vx + win_q_x.unsqueeze(3) + win_q_y.unsqueeze(4)  # add rel_x, rel_y\n",
    "        vx = self.softmax(vx.view(b, fh, fw, -1)).view(b, 1, fh, fw, kh, kw)\n",
    "\n",
    "        win_v = vv.unfold(2, kh, self.stride[0]).unfold(3, kw, self.stride[1])\n",
    "        # (b, fc, fh, fw, kh, kw) -> (b, fc, fh, fw)\n",
    "        fin_v = torch.einsum('bchwkl->bchw', (vx * win_v, ))\n",
    "\n",
    "        if self.bias is not None:\n",
    "            fin_v += self.bias\n",
    "\n",
    "        return fin_v\n",
    "\n",
    "# l = SelfAttentionConv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, groups=1)\n",
    "# l = SelfAttentionConv2d(16, 32, 3, stride=1, padding=1, groups=4)\n",
    "# x = torch.randn(3, 16, 8, 8)\n",
    "# l(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "# import time\n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# import torch.nn.init as init\n",
    "# from torch.nn.modules.utils import _pair\n",
    "\n",
    "\n",
    "# class SelfAttentionConv2d(nn.Module):\n",
    "#     def __init__(self, in_channels, out_channels, kernel_size,\n",
    "#                  stride=1, padding=0, groups=4, bias=True):\n",
    "#         super(SelfAttentionConv2d, self).__init__()\n",
    "#         if in_channels % groups != 0:\n",
    "#             raise ValueError('in_channels must be divisible by groups')\n",
    "#         if out_channels % groups != 0:\n",
    "#             raise ValueError('out_channels must be divisible by groups')\n",
    "#         self.in_channels = in_channels\n",
    "#         self.out_channels = out_channels\n",
    "#         self.kernel_size = _pair(kernel_size)\n",
    "#         self.stride = _pair(stride)\n",
    "#         self.padding = _pair(padding)\n",
    "#         self.groups = groups  # multi-head count\n",
    "\n",
    "#         if bias:\n",
    "#             self.bias = nn.Parameter(torch.Tensor(1, out_channels, 1, 1))\n",
    "#         else:\n",
    "#             self.register_parameter('bias', None)\n",
    "\n",
    "#         # relative position offsets are shared between multi-heads\n",
    "#         self.rel_size = (out_channels // groups) // 2\n",
    "#         self.relative_x = nn.Parameter(torch.Tensor(self.rel_size, self.kernel_size[1]))\n",
    "#         self.relative_y = nn.Parameter(torch.Tensor(\n",
    "#             (out_channels // groups) - self.rel_size, self.kernel_size[0]))\n",
    "\n",
    "#         self.weight_query = nn.Conv2d(self.in_channels, self.out_channels,\n",
    "#                                       1, groups=self.groups, bias=False)\n",
    "#         self.weight_key = nn.Conv2d(self.in_channels, self.out_channels,\n",
    "#                                     1, groups=self.groups, bias=False)\n",
    "#         self.weight_value = nn.Conv2d(self.in_channels, self.out_channels,\n",
    "#                                       1, groups=self.groups, bias=False)\n",
    "\n",
    "#         self.softmax = nn.Softmax(dim=3)\n",
    "\n",
    "#         self.reset_parameters()\n",
    "\n",
    "#     def reset_parameters(self):\n",
    "#         init.kaiming_normal_(self.weight_query.weight, mode='fan_out', nonlinearity='relu')\n",
    "#         init.kaiming_normal_(self.weight_key.weight, mode='fan_out', nonlinearity='relu')\n",
    "#         init.kaiming_normal_(self.weight_value.weight, mode='fan_out', nonlinearity='relu')\n",
    "\n",
    "#         if self.bias is not None:\n",
    "#             bound = 1 / math.sqrt(self.out_channels)\n",
    "#             init.uniform_(self.bias, -bound, bound)\n",
    "\n",
    "#         init.normal_(self.relative_x, 0, 1)\n",
    "#         init.normal_(self.relative_y, 0, 1)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         b, c, h, w = x.size()\n",
    "#         kh, kw = self.kernel_size\n",
    "#         ph, pw = h + self.padding[0] * 2, w + self.padding[1] * 2\n",
    "\n",
    "#         fh = (ph - kh) // self.stride[0] + 1\n",
    "#         fw = (pw - kw) // self.stride[1] + 1\n",
    "\n",
    "#         px, py = self.padding\n",
    "#         x = F.pad(x, (py, py, px, px))\n",
    "\n",
    "#         vq = self.weight_query(x)\n",
    "#         vk = self.weight_key(x)\n",
    "#         vv = self.weight_value(x)  # b, fc, ph, pw\n",
    "\n",
    "#         # b, fc, fh, fw\n",
    "#         win_q = vq[:, :, (kh - 1) // 2:ph - (kh // 2):self.stride[0],\n",
    "#                    (kw - 1) // 2:pw - (kw // 2):self.stride[1]]\n",
    "\n",
    "#         win_q_b = win_q.view(b, self.groups, -1, fh, fw)  # b, g, fc/g, fh, fw\n",
    "\n",
    "#         # (b, g, x, fh, fw), (b, g, y, fh, fw)\n",
    "#         win_q_x, win_q_y = win_q_b.split(self.rel_size, dim=2)\n",
    "#         win_q_x = torch.einsum('bgxhw,xk->bhwk', (win_q_x, self.relative_x))  # b, fh, fw, kw\n",
    "#         win_q_y = torch.einsum('bgyhw,yk->bhwk', (win_q_y, self.relative_y))  # b, fh, fw, kh\n",
    "\n",
    "#         win_k = vk.unfold(2, kh, self.stride[0]).unfold(\n",
    "#             3, kw, self.stride[1])  # b, fc, fh, fw, kh, kw\n",
    "\n",
    "#         vx = (win_q.unsqueeze(4).unsqueeze(4) * win_k).sum(dim=1)  # b, fh, fw, kh, kw\n",
    "#         vx = vx + win_q_x.unsqueeze(3) + win_q_y.unsqueeze(4)  # add rel_x, rel_y\n",
    "#         vx = self.softmax(vx.view(b, fh, fw, -1)).view(b, 1, fh, fw, kh, kw)\n",
    "\n",
    "#         win_v = vv.unfold(2, kh, self.stride[0]).unfold(3, kw, self.stride[1])\n",
    "#         # (b, fc, fh, fw, kh, kw) -> (b, fc, fh, fw)\n",
    "#         fin_v = torch.einsum('bchwkl->bchw', (vx * win_v, ))\n",
    "\n",
    "#         if self.bias is not None:\n",
    "#             fin_v += self.bias\n",
    "\n",
    "#         return fin_v\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Lib (RUN ME) - double-click to show/hide code\n",
    "####################\n",
    "## CORE\n",
    "#####################\n",
    "\n",
    "import inspect\n",
    "from collections import namedtuple, defaultdict\n",
    "from functools import partial\n",
    "import functools\n",
    "from itertools import chain, count, islice as take\n",
    "\n",
    "#####################\n",
    "## dict utils\n",
    "#####################\n",
    "\n",
    "union = lambda *dicts: {k: v for d in dicts for (k, v) in d.items()}\n",
    "\n",
    "make_tuple = lambda path: (path,) if isinstance(path, str) else path\n",
    "\n",
    "def path_iter(nested_dict, pfx=()):\n",
    "    for name, val in nested_dict.items():\n",
    "        if isinstance(val, dict): yield from path_iter(val, pfx+make_tuple(name))\n",
    "        else: yield (pfx+make_tuple(name), val)  \n",
    "            \n",
    "map_values = lambda func, dct: {k: func(v) for k,v in dct.items()}\n",
    "\n",
    "def map_nested(func, nested_dict):\n",
    "    return {k: map_nested(func, v) if isinstance(v, dict) else func(v) for k,v in nested_dict.items()}\n",
    "\n",
    "def group_by_key(seq):\n",
    "    res = defaultdict(list)\n",
    "    for k, v in seq: \n",
    "        res[k].append(v) \n",
    "    return res\n",
    "\n",
    "reorder = lambda dct, keys: {k: dct[k] for k in keys}\n",
    "\n",
    "#####################\n",
    "## graph building\n",
    "#####################\n",
    "\n",
    "def identity(value): return value\n",
    "\n",
    "def build_graph(net, path_map='_'.join):\n",
    "    net = {path: node if len(node) is 3 else (*node, None) for path, node in path_iter(net)}\n",
    "    default_inputs = chain([('input',)], net.keys())\n",
    "    resolve_path = lambda path, pfx: pfx+path if (pfx+path in net or not pfx) else resolve_path(net, path, pfx[:-1])\n",
    "    return {path_map(path): (typ, value, ([path_map(default)] if inputs is None else [path_map(resolve_path(make_tuple(k), path[:-1])) for k in inputs])) \n",
    "            for (path, (typ, value, inputs)), default in zip(net.items(), default_inputs)}\n",
    "\n",
    "#####################\n",
    "## network visualisation (requires pydot)\n",
    "#####################\n",
    "import IPython.display\n",
    "\n",
    "class ColorMap(dict):\n",
    "    palette = (\n",
    "        'bebada,ffffb3,fb8072,8dd3c7,80b1d3,fdb462,b3de69,fccde5,bc80bd,ccebc5,ffed6f,1f78b4,33a02c,e31a1c,ff7f00,'\n",
    "        '4dddf8,e66493,b07b87,4e90e3,dea05e,d0c281,f0e189,e9e8b1,e0eb71,bbd2a4,6ed641,57eb9c,3ca4d4,92d5e7,b15928'\n",
    "    ).split(',')\n",
    " \n",
    "    def __missing__(self, key):\n",
    "        self[key] = self.palette[len(self) % len(self.palette)]\n",
    "        return self[key]\n",
    "\n",
    "def make_pydot(nodes, edges, direction='LR', sep='_', **kwargs):\n",
    "    from pydot import Dot, Cluster, Node, Edge\n",
    "    class Subgraphs(dict):\n",
    "        def __missing__(self, path):\n",
    "            *parent, label = path\n",
    "            subgraph = Cluster(sep.join(path), label=label, style='rounded, filled', fillcolor='#77777744')\n",
    "            self[tuple(parent)].add_subgraph(subgraph)\n",
    "            return subgraph\n",
    "    g = Dot(rankdir=direction, directed=True, **kwargs)\n",
    "    g.set_node_defaults(\n",
    "        shape='box', style='rounded, filled', fillcolor='#ffffff')\n",
    "    subgraphs = Subgraphs({(): g})\n",
    "    for path, attr in nodes:\n",
    "        *parent, label = path.split(sep)\n",
    "        subgraphs[tuple(parent)].add_node(\n",
    "            Node(name=path, label=label, **attr))\n",
    "    for src, dst, attr in edges:\n",
    "        g.add_edge(Edge(src, dst, **attr))\n",
    "    return g\n",
    "\n",
    "class DotGraph():\n",
    "    colors = ColorMap()   \n",
    "    def __init__(self, graph, size=15, direction='LR'):\n",
    "        self.nodes = [(k, {\n",
    "            'tooltip': '%s %.1000r' % (typ, value), \n",
    "            'fillcolor': '#'+self.colors[typ],\n",
    "        }) for k, (typ, value, inputs) in graph.items()] \n",
    "        self.edges = [(src, k, {}) for (k, (_,_,inputs)) in graph.items() for src in inputs]\n",
    "        self.size, self.direction = size, direction\n",
    "\n",
    "    def dot_graph(self, **kwargs):\n",
    "        return make_pydot(self.nodes, self.edges, size=self.size, \n",
    "                            direction=self.direction, **kwargs)\n",
    "\n",
    "    def svg(self, **kwargs):\n",
    "        return self.dot_graph(**kwargs).create(format='svg').decode('utf-8')\n",
    "\n",
    "    try:\n",
    "        import pydot\n",
    "        def _repr_svg_(self):\n",
    "            return self.svg()\n",
    "    except ImportError:\n",
    "        def __repr__(self):\n",
    "            return 'pydot is needed for network visualisation'\n",
    "\n",
    "\n",
    "#####################\n",
    "## Layers\n",
    "##################### \n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from collections import namedtuple\n",
    "import copy\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "cpu = torch.device('cpu')\n",
    "    \n",
    "class Network(nn.Module):\n",
    "    def __init__(self, net, loss=None):\n",
    "        super().__init__()\n",
    "        self.graph = {path: (typ, typ(**params), inputs) for path, (typ, params, inputs) in build_graph(net).items()}\n",
    "        self.loss = loss or identity\n",
    "        for path, (_,node,_) in self.graph.items(): \n",
    "            setattr(self, path, node)\n",
    "    \n",
    "    def nodes(self):\n",
    "        return (node for _,node,_ in self.graph.values())\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        outputs = dict(inputs)\n",
    "        for k, (_, node, ins) in self.graph.items():\n",
    "            outputs[k] = node(*[outputs[x] for x in ins])\n",
    "        return outputs\n",
    "    \n",
    "    def half(self):\n",
    "        for node in self.nodes():\n",
    "            if isinstance(node, nn.Module) and not isinstance(node, nn.BatchNorm2d):\n",
    "                node.half()\n",
    "        return self\n",
    "\n",
    "build_model = lambda network, loss: Network(network, loss).half().to(device)\n",
    "show = lambda network, size=15: display(DotGraph(network.graph if isinstance(network, Network) else build_graph(network), size=size))\n",
    "    \n",
    "class Add(namedtuple('Add', [])):\n",
    "    def __call__(self, x, y): return x + y \n",
    "    \n",
    "class AddWeighted(namedtuple('AddWeighted', ['wx', 'wy'])):\n",
    "    def __call__(self, x, y): return self.wx*x + self.wy*y \n",
    "    \n",
    "class Identity(namedtuple('Identity', [])):\n",
    "    def __call__(self, x): return x\n",
    "\n",
    "class BatchNorm(nn.BatchNorm2d):\n",
    "    def __init__(self, num_features, eps=1e-05, momentum=0.1, weight=True, bias=True):\n",
    "        super().__init__(num_features, eps=eps, momentum=momentum)\n",
    "        self.weight.data.fill_(1.0)\n",
    "        self.bias.data.fill_(0.0)\n",
    "        self.weight.requires_grad = weight\n",
    "        self.bias.requires_grad = bias\n",
    "\n",
    "class GhostBatchNorm(BatchNorm):\n",
    "    def __init__(self, num_features, num_splits, **kw):\n",
    "        super().__init__(num_features, **kw)\n",
    "        self.num_splits = num_splits\n",
    "        self.register_buffer('running_mean', torch.zeros(num_features*self.num_splits))\n",
    "        self.register_buffer('running_var', torch.ones(num_features*self.num_splits))\n",
    "\n",
    "    def train(self, mode=True):\n",
    "        if (self.training is True) and (mode is False): #lazily collate stats when we are going to use them\n",
    "            self.running_mean = torch.mean(self.running_mean.view(self.num_splits, self.num_features), dim=0).repeat(self.num_splits)\n",
    "            self.running_var = torch.mean(self.running_var.view(self.num_splits, self.num_features), dim=0).repeat(self.num_splits)\n",
    "        return super().train(mode)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        N, C, H, W = input.shape\n",
    "        if self.training or not self.track_running_stats:\n",
    "            return F.batch_norm(\n",
    "                input.view(-1, C*self.num_splits, H, W), self.running_mean, self.running_var, \n",
    "                self.weight.repeat(self.num_splits), self.bias.repeat(self.num_splits),\n",
    "                True, self.momentum, self.eps).view(N, C, H, W) \n",
    "        else:\n",
    "            return F.batch_norm(\n",
    "                input, self.running_mean[:self.num_features], self.running_var[:self.num_features], \n",
    "                self.weight, self.bias, False, self.momentum, self.eps)\n",
    "        \n",
    "class Mul(nn.Module):\n",
    "    def __init__(self, weight):\n",
    "        super().__init__()\n",
    "        self.weight = weight\n",
    "    def __call__(self, x): \n",
    "        return x*self.weight\n",
    "    \n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x): \n",
    "        return x.view(x.size(0), x.size(1))\n",
    "\n",
    "# Losses\n",
    "class CrossEntropyLoss(namedtuple('CrossEntropyLoss', [])):\n",
    "    def __call__(self, log_probs, target):\n",
    "        return torch.nn.functional.nll_loss(log_probs, target, reduction='none')\n",
    "    \n",
    "class KLLoss(namedtuple('KLLoss', [])):        \n",
    "    def __call__(self, log_probs):\n",
    "        return -log_probs.mean(dim=1)\n",
    "\n",
    "class Correct(namedtuple('Correct', [])):\n",
    "    def __call__(self, classifier, target):\n",
    "        return classifier.max(dim = 1)[1] == target\n",
    "\n",
    "class LogSoftmax(namedtuple('LogSoftmax', ['dim'])):\n",
    "    def __call__(self, x):\n",
    "        return torch.nn.functional.log_softmax(x, self.dim, _stacklevel=5)\n",
    "\n",
    "    \n",
    "# node definitions   \n",
    "from inspect import signature    \n",
    "empty_signature = inspect.Signature()\n",
    "\n",
    "class node_def(namedtuple('node_def', ['type'])):\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return (self.type, dict(signature(self.type).bind(*args, **kwargs).arguments))\n",
    "\n",
    "conv = node_def(nn.Conv2d)\n",
    "conv_fancy = node_def(SelfAttentionConv2d)\n",
    "linear = node_def(nn.Linear)\n",
    "batch_norm = node_def(BatchNorm)\n",
    "pool = node_def(nn.MaxPool2d)\n",
    "relu = node_def(nn.ReLU)\n",
    "\n",
    "def map_types(mapping, net):\n",
    "    def f(node):\n",
    "        typ, *rest = node\n",
    "        return (mapping.get(typ, typ), *rest)\n",
    "    return map_nested(f, net) \n",
    "\n",
    "#####################\n",
    "## Compat\n",
    "##################### \n",
    "\n",
    "def to_numpy(x):\n",
    "    if isinstance(x, torch.Tensor):\n",
    "        return x.detach().cpu().numpy()  \n",
    "    return x\n",
    "  \n",
    "def flip_lr(x):\n",
    "    if isinstance(x, torch.Tensor):\n",
    "        return torch.flip(x, [-1]) \n",
    "    return x[..., ::-1].copy()\n",
    "  \n",
    "trainable_params = lambda model: {k:p for k,p in model.named_parameters() if p.requires_grad}\n",
    "\n",
    "#####################\n",
    "## Optimisers\n",
    "##################### \n",
    "\n",
    "from functools import partial\n",
    "\n",
    "def nesterov_update(w, dw, v, lr, weight_decay, momentum):\n",
    "    dw.add_(weight_decay, w).mul_(-lr)\n",
    "    v.mul_(momentum).add_(dw)\n",
    "    w.add_(dw.add_(momentum, v))\n",
    "\n",
    "norm = lambda x: torch.norm(x.reshape(x.size(0),-1).float(), dim=1)[:,None,None,None]\n",
    "\n",
    "def LARS_update(w, dw, v, lr, weight_decay, momentum):\n",
    "    nesterov_update(w, dw, v, lr*(norm(w)/(norm(dw)+1e-2)).to(w.dtype), weight_decay, momentum)\n",
    "\n",
    "def zeros_like(weights):\n",
    "    return [torch.zeros_like(w) for w in weights]\n",
    "\n",
    "def optimiser(weights, param_schedule, update, state_init):\n",
    "    weights = list(weights)\n",
    "    return {'update': update, 'param_schedule': param_schedule, 'step_number': 0, 'weights': weights,  'opt_state': state_init(weights)}\n",
    "\n",
    "def opt_step(update, param_schedule, step_number, weights, opt_state):\n",
    "    step_number += 1\n",
    "    param_values = {k: f(step_number) for k, f in param_schedule.items()}\n",
    "    for w, v in zip(weights, opt_state):\n",
    "        if w.requires_grad:\n",
    "            update(w.data, w.grad.data, v, **param_values)\n",
    "    return {'update': update, 'param_schedule': param_schedule, 'step_number': step_number, 'weights': weights,  'opt_state': opt_state}\n",
    "\n",
    "LARS = partial(optimiser, update=LARS_update, state_init=zeros_like)\n",
    "SGD = partial(optimiser, update=nesterov_update, state_init=zeros_like)\n",
    "  \n",
    "class PiecewiseLinear(namedtuple('PiecewiseLinear', ('knots', 'vals'))):\n",
    "    def __call__(self, t):\n",
    "        return np.interp([t], self.knots, self.vals)[0]\n",
    "     \n",
    "class Const(namedtuple('Const', ['val'])):\n",
    "    def __call__(self, x):\n",
    "        return self.val\n",
    "\n",
    "#####################\n",
    "## DATA\n",
    "##################### \n",
    "\n",
    "import torchvision\n",
    "from functools import lru_cache as cache\n",
    "\n",
    "@cache(None)\n",
    "def cifar10(root='./data'):\n",
    "    download = lambda train: torchvision.datasets.CIFAR10(root=root, train=train, download=True)\n",
    "    return {k: {'data': torch.tensor(v.data), 'targets': torch.tensor(v.targets)} \n",
    "            for k,v in [('train', download(True)), ('valid', download(False))]}\n",
    "  \n",
    "cifar10_mean, cifar10_std = [\n",
    "    (125.31, 122.95, 113.87), # equals np.mean(cifar10()['train']['data'], axis=(0,1,2)) \n",
    "    (62.99, 62.09, 66.70), # equals np.std(cifar10()['train']['data'], axis=(0,1,2))\n",
    "]\n",
    "cifar10_classes= 'airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck'.split(', ')\n",
    "\n",
    "#####################\n",
    "## data preprocessing\n",
    "#####################\n",
    "mean, std = [torch.tensor(x, device=device, dtype=torch.float16) for x in (cifar10_mean, cifar10_std)]\n",
    "\n",
    "normalise = lambda data, mean=mean, std=std: (data - mean)/std\n",
    "unnormalise = lambda data, mean=mean, std=std: data*std + mean\n",
    "pad = lambda data, border: nn.ReflectionPad2d(border)(data)\n",
    "transpose = lambda x, source='NHWC', target='NCHW': x.permute([source.index(d) for d in target]) \n",
    "to = lambda *args, **kwargs: (lambda x: x.to(*args, **kwargs))\n",
    "\n",
    "def preprocess(dataset, transforms):\n",
    "    dataset = copy.copy(dataset)\n",
    "    for transform in reversed(transforms):\n",
    "        dataset['data'] = transform(dataset['data'])\n",
    "    return dataset\n",
    "\n",
    "#####################\n",
    "## Data augmentation\n",
    "#####################\n",
    "\n",
    "chunks = lambda data, splits: (data[start:end] for (start, end) in zip(splits, splits[1:]))\n",
    "\n",
    "even_splits = lambda N, num_chunks: np.cumsum([0] + [(N//num_chunks)+1]*(N % num_chunks)  + [N//num_chunks]*(num_chunks - (N % num_chunks)))\n",
    "\n",
    "def shuffled(xs, inplace=False):\n",
    "    xs = xs if inplace else copy.copy(xs) \n",
    "    np.random.shuffle(xs)\n",
    "    return xs\n",
    "\n",
    "def transformed(data, targets, transform, max_options=None, unshuffle=False):\n",
    "    i = torch.randperm(len(data), device=device)\n",
    "    data = data[i]\n",
    "    options = shuffled(transform.options(data.shape), inplace=True)[:max_options]\n",
    "    data = torch.cat([transform.apply(x, **choice) for choice, x in zip(options, chunks(data, even_splits(len(data), len(options))))])\n",
    "    return (data[torch.argsort(i)], targets) if unshuffle else (data, targets[i])\n",
    "\n",
    "class Batches():\n",
    "    def __init__(self, batch_size, transforms=(), dataset=None, shuffle=True, drop_last=False, max_options=None):\n",
    "        self.dataset, self.transforms, self.shuffle, self.max_options = dataset, transforms, shuffle, max_options\n",
    "        N = len(dataset['data'])\n",
    "        self.splits = list(range(0, N+1, batch_size))\n",
    "        if not drop_last and self.splits[-1] != N:\n",
    "            self.splits.append(N)\n",
    "     \n",
    "    def __iter__(self):\n",
    "        data, targets = self.dataset['data'], self.dataset['targets']\n",
    "        for transform in self.transforms:\n",
    "            data, targets = transformed(data, targets, transform, max_options=self.max_options, unshuffle=not self.shuffle)\n",
    "        if self.shuffle:\n",
    "            i = torch.randperm(len(data), device=device)\n",
    "            data, targets = data[i], targets[i]\n",
    "        return ({'input': x.clone(), 'target': y} for (x, y) in zip(chunks(data, self.splits), chunks(targets, self.splits)))\n",
    "    \n",
    "    def __len__(self): \n",
    "        return len(self.splits) - 1\n",
    "    \n",
    "#####################\n",
    "## Augmentations\n",
    "#####################\n",
    "\n",
    "class Crop(namedtuple('Crop', ('h', 'w'))):\n",
    "    def apply(self, x, x0, y0):\n",
    "        return x[..., y0:y0+self.h, x0:x0+self.w] \n",
    "\n",
    "    def options(self, shape):\n",
    "        *_, H, W = shape\n",
    "        return [{'x0': x0, 'y0': y0} for x0 in range(W+1-self.w) for y0 in range(H+1-self.h)]\n",
    "    \n",
    "class FlipLR(namedtuple('FlipLR', ())):\n",
    "    def apply(self, x, choice):\n",
    "        return flip_lr(x) if choice else x \n",
    "        \n",
    "    def options(self, shape):\n",
    "        return [{'choice': b} for b in [True, False]]\n",
    "\n",
    "class Cutout(namedtuple('Cutout', ('h', 'w'))):\n",
    "    def apply(self, x, x0, y0):\n",
    "        x[..., y0:y0+self.h, x0:x0+self.w] = 0.0\n",
    "        return x\n",
    "\n",
    "    def options(self, shape):\n",
    "        *_, H, W = shape\n",
    "        return [{'x0': x0, 'y0': y0} for x0 in range(W+1-self.w) for y0 in range(H+1-self.h)]  \n",
    "\n",
    "#####################\n",
    "## TRAINING\n",
    "#####################\n",
    "\n",
    "import time\n",
    "\n",
    "class Timer():\n",
    "    def __init__(self, synch=None):\n",
    "        self.synch = synch or (lambda: None)\n",
    "        self.synch()\n",
    "        self.times = [time.perf_counter()]\n",
    "        self.total_time = 0.0\n",
    "\n",
    "    def __call__(self, update_total=True):\n",
    "        self.synch()\n",
    "        self.times.append(time.perf_counter())\n",
    "        delta_t = self.times[-1] - self.times[-2]\n",
    "        if update_total:\n",
    "            self.total_time += delta_t\n",
    "        return delta_t\n",
    "\n",
    "default_table_formats = {float: '{:{w}.4f}', str: '{:>{w}s}', 'default': '{:{w}}', 'title': '{:>{w}s}'}\n",
    "\n",
    "def table_formatter(val, is_title=False, col_width=12, formats=None):\n",
    "    formats = formats or default_table_formats\n",
    "    type_ = lambda val: float if isinstance(val, (float, np.float)) else type(val)\n",
    "    return (formats['title'] if is_title else formats.get(type_(val), formats['default'])).format(val, w=col_width)\n",
    "\n",
    "every = lambda n, col: (lambda data: data[col] % n == 0)\n",
    "\n",
    "class Table():\n",
    "    def __init__(self, keys=None, report=(lambda data: True), formatter=table_formatter):\n",
    "        self.keys, self.report, self.formatter = keys, report, formatter\n",
    "        self.log = []\n",
    "        \n",
    "    def append(self, data):\n",
    "        self.log.append(data)\n",
    "        data = {' '.join(p): v for p,v in path_iter(data)}\n",
    "        self.keys = self.keys or data.keys()\n",
    "        if len(self.log) is 1:\n",
    "            print(*(self.formatter(k, True) for k in self.keys))\n",
    "        if self.report(data):\n",
    "            print(*(self.formatter(data[k]) for k in self.keys))\n",
    "            \n",
    "    def df(self):\n",
    "        return pd.DataFrame([{'_'.join(p): v for p,v in path_iter(row)} for row in self.log])     \n",
    "            \n",
    "def reduce(batches, state, steps):\n",
    "    #state: is a dictionary\n",
    "    #steps: are functions that take (batch, state)\n",
    "    #and return a dictionary of updates to the state (or None)\n",
    "    \n",
    "    for batch in chain(batches, [None]): \n",
    "    #we send an extra batch=None at the end for steps that \n",
    "    #need to do some tidying-up (e.g. log_activations)\n",
    "        for step in steps:\n",
    "            updates = step(batch, state)\n",
    "            if updates:\n",
    "                for k,v in updates.items():\n",
    "                    state[k] = v                  \n",
    "    return state\n",
    "  \n",
    "#define keys in the state dict as constants\n",
    "MODEL = 'model'\n",
    "VALID_MODEL = 'valid_model'\n",
    "OUTPUT = 'output'\n",
    "OPTS = 'optimisers'\n",
    "ACT_LOG = 'activation_log'\n",
    "WEIGHT_LOG = 'weight_log'\n",
    "\n",
    "#step definitions\n",
    "def forward(training_mode):\n",
    "    def step(batch, state):\n",
    "        if not batch: return\n",
    "        model = state[MODEL] if training_mode or (VALID_MODEL not in state) else state[VALID_MODEL]\n",
    "        if model.training != training_mode: #without the guard it's slow!\n",
    "            model.train(training_mode)\n",
    "        return {OUTPUT: model.loss(model(batch))}\n",
    "    return step\n",
    "\n",
    "def forward_tta(tta_transforms):\n",
    "    def step(batch, state):\n",
    "        if not batch: return\n",
    "        model = state[MODEL] if (VALID_MODEL not in state) else state[VALID_MODEL]\n",
    "        if model.training:\n",
    "            model.train(False)\n",
    "        logits = torch.mean(torch.stack([model({'input': transform(batch['input'].clone())})['logits'].detach() for transform in tta_transforms], dim=0), dim=0)\n",
    "        return {OUTPUT: model.loss(dict(batch, logits=logits))}\n",
    "    return step\n",
    "\n",
    "def backward(dtype=torch.float16):\n",
    "    def step(batch, state):\n",
    "        state[MODEL].zero_grad()\n",
    "        if not batch: return\n",
    "        state[OUTPUT]['loss'].to(dtype).sum().backward()\n",
    "    return step\n",
    "\n",
    "def opt_steps(batch, state):\n",
    "    if not batch: return\n",
    "    return {OPTS: [opt_step(**opt) for opt in state[OPTS]]}\n",
    "\n",
    "def log_activations(node_names=('loss', 'acc')):\n",
    "    logs = []\n",
    "    def step(batch, state):\n",
    "        if batch:\n",
    "            logs.extend((k, state[OUTPUT][k].detach()) for k in node_names)\n",
    "        else:\n",
    "            res = map_values((lambda xs: to_numpy(torch.cat(xs)).astype(np.float)), group_by_key(logs))\n",
    "            logs.clear()\n",
    "            return {ACT_LOG: res}\n",
    "    return step\n",
    "\n",
    "def update_ema(momentum, update_freq=1):\n",
    "    n = iter(count())\n",
    "    rho = momentum**update_freq\n",
    "    def step(batch, state):\n",
    "        if not batch: return\n",
    "        if (next(n) % update_freq) != 0: return\n",
    "        for v, ema_v in zip(state[MODEL].state_dict().values(), state[VALID_MODEL].state_dict().values()):\n",
    "            ema_v *= rho\n",
    "            ema_v += (1-rho)*v\n",
    "    return step\n",
    "\n",
    "train_steps = (forward(training_mode=True), log_activations(('loss', 'acc')), backward(), opt_steps)\n",
    "valid_steps = (forward(training_mode=False), log_activations(('loss', 'acc')))\n",
    "\n",
    "epoch_stats = lambda state: {k: np.mean(v) for k, v in state[ACT_LOG].items()}\n",
    "\n",
    "def train_epoch(state, timer, train_batches, valid_batches, train_steps=train_steps, valid_steps=valid_steps, on_epoch_end=identity):\n",
    "    train_summary, train_time = epoch_stats(on_epoch_end(reduce(train_batches, state, train_steps))), timer()\n",
    "    valid_summary, valid_time = epoch_stats(reduce(valid_batches, state, valid_steps)), timer(update_total=False) #DAWNBench rules\n",
    "    return {\n",
    "        'train': union({'time': train_time}, train_summary), \n",
    "        'valid': union({'time': valid_time}, valid_summary), \n",
    "        'total time': timer.total_time\n",
    "    }\n",
    "\n",
    "summary = lambda logs, cols=['valid_acc']: logs.df().query('epoch==epoch.max()')[cols].describe().transpose().astype({'count': int})[\n",
    "    ['count', 'mean', 'min', 'max', 'std']]\n",
    "\n",
    "#on_epoch_end\n",
    "def log_weights(state, weights):\n",
    "    state[WEIGHT_LOG] = state.get(WEIGHT_LOG, [])\n",
    "    state[WEIGHT_LOG].append({k: to_numpy(v.data) for k,v in weights.items()})\n",
    "    return state\n",
    "\n",
    "def fine_tune_bn_stats(state, batches, model_key=VALID_MODEL):\n",
    "    reduce(batches, {MODEL: state[model_key]}, [forward(True)])\n",
    "    return state\n",
    "\n",
    "#misc\n",
    "def warmup_cudnn(model, batch):\n",
    "    #run forward and backward pass of the model\n",
    "    #to allow benchmarking of cudnn kernels \n",
    "    reduce([batch], {MODEL: model}, [forward(True), backward()])\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "\n",
    "#####################\n",
    "## Plotting\n",
    "#####################\n",
    "\n",
    "import altair as alt\n",
    "alt.renderers.enable('colab')\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import SVG\n",
    "\n",
    "def empty_plot(ax, **kw):\n",
    "    ax.axis('off')\n",
    "    return ax\n",
    "\n",
    "def image_plot(ax, img, title):\n",
    "    ax.imshow(to_numpy(unnormalise(transpose(img, 'CHW', 'HWC'))).astype(np.int))\n",
    "    ax.set_title(title)\n",
    "    ax.axis('off')\n",
    "\n",
    "def layout(figures, sharex=False, sharey=False, figure_title=None, col_width=4, row_height = 3.25, **kw):\n",
    "    nrows, ncols = np.array(figures).shape\n",
    "\n",
    "    fig, axs = plt.subplots(nrows=nrows, ncols=ncols, sharex=sharex, sharey=sharey, figsize=(col_width*ncols, row_height*nrows))\n",
    "    axs = [figure(ax, **kw) for row in zip(np.array(axs).reshape(nrows, ncols), figures) for ax, figure in zip(*row)]\n",
    "    fig.suptitle(figure_title)\n",
    "    return fig, axs\n",
    "\n",
    "#####################\n",
    "## Network\n",
    "#####################\n",
    "\n",
    "def conv_block(c_in, c_out):\n",
    "    if c_in >= 256:\n",
    "        return {\n",
    "            'conv': conv_fancy(\n",
    "                in_channels=c_in, out_channels=c_out, kernel_size=(7, 7),\n",
    "                stride=(1, 1), padding=(3, 3), bias=False, groups=8), \n",
    "            'norm': batch_norm(c_out), \n",
    "            'act':  relu(),\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            'conv': conv(in_channels=c_in, out_channels=c_out, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), \n",
    "            'norm': batch_norm(c_out), \n",
    "            'act':  relu(),\n",
    "        }\n",
    "\n",
    "conv_pool_block = lambda c_in, c_out: dict(conv_block(c_in, c_out), pool=pool(2))\n",
    "conv_pool_block_pre = lambda c_in, c_out: reorder(conv_pool_block(c_in, c_out), ('conv', 'pool', 'norm', 'act'))\n",
    "\n",
    "residual = lambda c, conv_block: {\n",
    "    'in': (Identity, {}),\n",
    "    'res1': conv_block(c, c),\n",
    "    'res2': conv_block(c, c),\n",
    "    'out': (Identity, {}),\n",
    "    'add': (Add, {}, ['in', 'out']),\n",
    "}\n",
    "\n",
    "def build_network(channels, extra_layers, res_layers, scale, conv_block=conv_block, \n",
    "                  prep_block=conv_block, conv_pool_block=conv_pool_block, types=None): \n",
    "    net = {\n",
    "        'prep': prep_block(3, channels['prep']),\n",
    "        'layer1': conv_pool_block(channels['prep'], channels['layer1']),\n",
    "        'layer2': conv_pool_block(channels['layer1'], channels['layer2']),\n",
    "        'layer3': conv_pool_block(channels['layer2'], channels['layer3']),\n",
    "        'pool': pool(4),\n",
    "        'classifier': {\n",
    "            'flatten': (Flatten, {}),\n",
    "            'conv': linear(channels['layer3'], 10, bias=False),\n",
    "            'scale': (Mul, {'weight': scale}),\n",
    "        },\n",
    "        'logits': (Identity, {}),\n",
    "    }\n",
    "    for layer in res_layers:\n",
    "        net[layer]['residual'] = residual(channels[layer], conv_block)\n",
    "    for layer in extra_layers:\n",
    "        net[layer]['extra'] = conv_block(channels[layer], channels[layer])     \n",
    "    if types: net = map_types(types, net)\n",
    "    return net\n",
    "\n",
    "channels={'prep': 64, 'layer1': 128, 'layer2': 256, 'layer3': 512}\n",
    "network = partial(build_network, channels=channels, extra_layers=(), res_layers=('layer1', 'layer3'), scale=1/8)   \n",
    "\n",
    "x_ent_loss = Network({\n",
    "  'loss':  (nn.CrossEntropyLoss, {'reduction': 'none'}, ['logits', 'target']),\n",
    "  'acc': (Correct, {}, ['logits', 'target'])\n",
    "})\n",
    "\n",
    "label_smoothing_loss = lambda alpha: Network({\n",
    "        'logprobs': (LogSoftmax, {'dim': 1}, ['logits']),\n",
    "        'KL':  (KLLoss, {}, ['logprobs']),\n",
    "        'xent':  (CrossEntropyLoss, {}, ['logprobs', 'target']),\n",
    "        'loss': (AddWeighted, {'wx': 1-alpha, 'wy': alpha}, ['xent', 'KL']),\n",
    "        'acc': (Correct, {}, ['logits', 'target']),\n",
    "    })\n",
    "\n",
    "#####################\n",
    "## Misc\n",
    "#####################\n",
    "\n",
    "lr_schedule = lambda knots, vals, batch_size: PiecewiseLinear(np.array(knots)*len(train_batches(batch_size)), np.array(vals)/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Starting timer\n",
      "Transfer to GPU:\t0.042s\n",
      "Data preprocessing:\t0.031s\n",
      "Transfer to CPU:\t0.353s\n"
     ]
    }
   ],
   "source": [
    "#####################\n",
    "## timings\n",
    "#####################\n",
    "dataset = cifar10() #downloads dataset\n",
    "print('Starting timer')\n",
    "t = Timer(synch=torch.cuda.synchronize)\n",
    "dataset = map_nested(to(device), dataset)\n",
    "print(f'Transfer to GPU:\\t{t():.3f}s')\n",
    "train_set = preprocess(dataset['train'], [partial(pad, border=4), transpose, normalise, to(torch.float16)])\n",
    "valid_set = preprocess(dataset['valid'], [transpose, normalise, to(torch.float16)])\n",
    "print(f'Data preprocessing:\\t{t():.3f}s')\n",
    "map_nested(to(cpu), {'train': train_set, 'valid': valid_set})\n",
    "print(f'Transfer to CPU:\\t{t():.3f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches = partial(Batches, dataset=train_set, shuffle=True,  drop_last=True, max_options=200)\n",
    "valid_batches = partial(Batches, dataset=valid_set, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batches = train_batches(batch_size=8, transforms=(Crop(32, 32), FlipLR(), Cutout(8, 8)), shuffle=False)\n",
    "\n",
    "# layout([[partial(image_plot, img=x, title=cifar10_classes[y]) for x,y in zip(*next(iter(batches)).values())]], col_width=2, row_height=2)\n",
    "# layout([[partial(image_plot, img=x, title=cifar10_classes[y]) for x,y in zip(*next(iter(batches)).values())]], col_width=2, row_height=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Timer(synch=torch.cuda.synchronize)\n",
    "batches = train_batches(batch_size=512, transforms=(Crop(32, 32), FlipLR(), Cutout(8, 8)))\n",
    "\n",
    "# for epoch in range(24):\n",
    "#     for batch in batches:\n",
    "#         pass\n",
    "# print(f'{t():.3f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pydot is needed for network visualisation"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "baseline_net=network()\n",
    "show(baseline_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_channels, out_channels, kernel_size, stride, padding, groups\n",
      "256 512 (7, 7) (1, 1) (3, 3) 8\n",
      "in_channels, out_channels, kernel_size, stride, padding, groups\n",
      "512 512 (7, 7) (1, 1) (3, 3) 8\n",
      "in_channels, out_channels, kernel_size, stride, padding, groups\n",
      "512 512 (7, 7) (1, 1) (3, 3) 8\n",
      "       epoch   train time   train loss    train acc   valid time   valid loss    valid acc   total time\n",
      "           1      69.6707       1.8819       0.2980       2.7039       1.8914       0.2932      69.6707\n",
      "           2      69.0904       1.4840       0.4528       2.5491       1.2782       0.5339     138.7611\n",
      "           3      68.5713       1.0901       0.6094       2.5521       0.9785       0.6502     207.3324\n",
      "           4      68.6708       0.9259       0.6732       2.5522       1.0762       0.6204     276.0033\n",
      "           5      69.8984       0.8438       0.7044       2.5530       1.0530       0.6528     345.9017\n",
      "           6      71.1861       0.7728       0.7290       2.5546       0.8262       0.7160     417.0877\n",
      "           7      71.4684       0.7231       0.7492       2.5549       0.8642       0.6931     488.5561\n",
      "           8      71.7701       0.6848       0.7631       2.5524       0.8711       0.6998     560.3262\n",
      "           9      71.9990       0.6487       0.7760       2.5557       0.7822       0.7284     632.3252\n",
      "          10      72.0720       0.6237       0.7853       2.5527       0.6024       0.7946     704.3972\n",
      "          11      72.0738       0.5962       0.7946       2.5546       0.6768       0.7678     776.4710\n",
      "          12      72.0998       0.5707       0.8043       2.5542       0.7836       0.7248     848.5708\n"
     ]
    }
   ],
   "source": [
    "# With groups=32, my fix, >=256, 256 batch size\n",
    "epochs, batch_size = 24, 256\n",
    "transforms = (Crop(32, 32), FlipLR(), Cutout(8, 8))\n",
    "opt_params = {'lr': lr_schedule([0, 5, epochs], [0.0, 0.4, 0.0], batch_size),\n",
    "              'weight_decay': Const(5e-4*512), 'momentum': Const(0.9)}\n",
    "\n",
    "model = build_model(baseline_net, x_ent_loss)  \n",
    "warmup_cudnn(model, next(iter(train_batches(batch_size, transforms))))\n",
    "logs, state, timer = Table(), {MODEL: model, OPTS: [SGD(trainable_params(model).values(), opt_params)]}, Timer(torch.cuda.synchronize)\n",
    "for epoch in range(epochs):\n",
    "    logs.append(union({'epoch': epoch+1}, train_epoch(state, timer, train_batches(batch_size, transforms), valid_batches(batch_size))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_channels, out_channels, kernel_size, stride, padding, groups\n",
      "128 128 (3, 3) (1, 1) (1, 1) 8\n",
      "in_channels, out_channels, kernel_size, stride, padding, groups\n",
      "128 128 (3, 3) (1, 1) (1, 1) 8\n",
      "in_channels, out_channels, kernel_size, stride, padding, groups\n",
      "128 256 (3, 3) (1, 1) (1, 1) 8\n",
      "in_channels, out_channels, kernel_size, stride, padding, groups\n",
      "256 512 (3, 3) (1, 1) (1, 1) 8\n",
      "in_channels, out_channels, kernel_size, stride, padding, groups\n",
      "512 512 (3, 3) (1, 1) (1, 1) 8\n",
      "in_channels, out_channels, kernel_size, stride, padding, groups\n",
      "512 512 (3, 3) (1, 1) (1, 1) 8\n",
      "       epoch   train time   train loss    train acc   valid time   valid loss    valid acc   total time\n",
      "           1      76.5457       1.9604       0.2673       3.8145       1.8175       0.3171      76.5457\n"
     ]
    }
   ],
   "source": [
    "# With groups=8, my fix, >=128, smaller batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "128\n",
      "128\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "       epoch   train time   train loss    train acc   valid time   valid loss    valid acc   total time\n",
      "           1      78.3379       1.9781       0.2692       3.8851       1.6775       0.3778      78.3379\n",
      "           2      75.3531       1.5593       0.4309       3.7363       1.6552       0.4036     153.6911\n"
     ]
    }
   ],
   "source": [
    "# With groups=16, my fix, >=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       epoch   train time   train loss    train acc   valid time   valid loss    valid acc   total time\n",
      "           1      25.4882       2.0187       0.2412       1.6091       1.9932       0.2733      25.4882\n",
      "           2      25.0593       1.7506       0.3460       1.3917       2.0299       0.3032      50.5475\n",
      "           3      24.9676       1.5479       0.4308       1.3980       1.3964       0.4710      75.5151\n"
     ]
    }
   ],
   "source": [
    "# With groups=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       epoch   train time   train loss    train acc   valid time   valid loss    valid acc   total time\n",
      "           1      27.8906       1.8099       0.3463       1.6154       1.5508       0.4278      27.8906\n",
      "           2      27.2454       1.2260       0.5566       1.3939       1.1010       0.6127      55.1361\n"
     ]
    }
   ],
   "source": [
    "# With groups=32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       epoch   train time   train loss    train acc   valid time   valid loss    valid acc   total time\n",
      "           1      25.8910       1.8289       0.3256       1.6184       2.0635       0.3187      25.8910\n",
      "           2      25.0553       1.2330       0.5535       1.3669       1.0868       0.6169      50.9463\n",
      "           3      24.9529       0.9727       0.6520       1.3752       0.9874       0.6512      75.8992\n",
      "           4      25.2641       0.8501       0.7015       1.3700       1.0561       0.6209     101.1632\n"
     ]
    }
   ],
   "source": [
    "# Last two layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       epoch   train time   train loss    train acc   valid time   valid loss    valid acc   total time\n",
      "           1      14.5337       1.8235       0.3338       1.0552       1.4650       0.4648      14.5337\n",
      "           2      14.4026       1.1586       0.5821       0.8097       0.9150       0.6697      28.9362\n",
      "           3      14.4553       0.8566       0.6977       0.8049       0.7660       0.7268      43.3916\n",
      "           4      14.4485       0.7251       0.7467       0.8148       0.8596       0.7112      57.8401\n",
      "           5      14.5239       0.6514       0.7742       0.8125       0.6686       0.7655      72.3640\n",
      "           6      14.7088       0.5859       0.7983       0.8154       0.6772       0.7657      87.0728\n",
      "           7      14.8302       0.5363       0.8170       0.8096       0.7600       0.7455     101.9030\n"
     ]
    }
   ],
   "source": [
    "# With conv fancy on final conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       epoch   train time   train loss    train acc   valid time   valid loss    valid acc   total time\n",
      "           1       8.6170       1.6447       0.4084       0.9453       1.2173       0.5464       8.6170\n",
      "           2       8.6378       0.9551       0.6590       0.5448       0.8977       0.6963      17.2548\n",
      "           3       8.6384       0.7367       0.7407       0.5468       0.6215       0.7845      25.8932\n",
      "           4       8.6563       0.6254       0.7826       0.5456       0.7033       0.7602      34.5494\n",
      "           5       8.6655       0.5611       0.8066       0.5472       0.6971       0.7669      43.2149\n",
      "           6       8.6796       0.4990       0.8281       0.5473       0.5102       0.8286      51.8946\n",
      "           7       8.6701       0.4504       0.8469       0.5478       0.6228       0.7816      60.5646\n",
      "           8       8.6845       0.4114       0.8598       0.5474       0.5754       0.8010      69.2491\n"
     ]
    }
   ],
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p36'\n'",
   "language": "python",
   "name": "p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
