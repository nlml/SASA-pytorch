{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "16\n",
      "32\n",
      "32\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.667064\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.543031\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.494371\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.202603\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.374248\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.353106\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.166518\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.226286\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.311429\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.238201\n",
      "\n",
      "Test set: Average loss: 0.1692, Accuracy: 9455/10000 (95%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.117806\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.287478\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.202857\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.332115\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.058376\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.172487\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.137455\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.267850\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.259820\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.142391\n",
      "\n",
      "Test set: Average loss: 0.1326, Accuracy: 9557/10000 (96%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.174323\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.154590\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.136409\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.183086\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.080675\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.049674\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.117159\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.203330\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.080670\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.082488\n",
      "\n",
      "Test set: Average loss: 0.1046, Accuracy: 9670/10000 (97%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.307799\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.118548\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.114958\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.096247\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.066694\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.129211\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.052694\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.102369\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.254636\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.102556\n",
      "\n",
      "Test set: Average loss: 0.0753, Accuracy: 9758/10000 (98%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.033119\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.076181\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.040204\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.016292\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.133549\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.081199\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.222809\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.094547\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.068690\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.105461\n",
      "\n",
      "Test set: Average loss: 0.0726, Accuracy: 9759/10000 (98%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.180752\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.196616\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.081466\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.172771\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.117952\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.035262\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.060281\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.238389\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.044760\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.157444\n",
      "\n",
      "Test set: Average loss: 0.0602, Accuracy: 9809/10000 (98%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.135305\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.129796\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.017414\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.153713\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.055438\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.114528\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.117560\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.077642\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.171985\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.077487\n",
      "\n",
      "Test set: Average loss: 0.0594, Accuracy: 9798/10000 (98%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.178639\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.081361\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.069200\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.042270\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.210796\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.047518\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.099816\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.042822\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.122518\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.148647\n",
      "\n",
      "Test set: Average loss: 0.0570, Accuracy: 9797/10000 (98%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.074012\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.034112\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.321993\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.081801\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.022075\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.103394\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.060888\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.058208\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.052820\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.132444\n",
      "\n",
      "Test set: Average loss: 0.0539, Accuracy: 9825/10000 (98%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.079404\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.091446\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.089654\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.048287\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.040757\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.093207\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.172805\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.040439\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.232317\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.150134\n",
      "\n",
      "Test set: Average loss: 0.0539, Accuracy: 9818/10000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        Conv2dUse = nn.Conv2d\n",
    "        Conv2dUse = SelfAttentionConv2d\n",
    "        self.conv1 = nn.Conv2d(1, 16, 5, 1)\n",
    "        self.bn1 = nn.BatchNorm2d(self.conv1.weight.shape[0])\n",
    "        self.conv2 = Conv2dUse(16, 32, 5, 1, padding=2)\n",
    "        self.bn2 = nn.BatchNorm2d(self.conv2.weight.shape[0])\n",
    "        self.conv3 = Conv2dUse(32, 64, 5, 1, padding=2)\n",
    "        self.bn3 = nn.BatchNorm2d(self.conv3.weight.shape[0])\n",
    "        self.drop = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(64*3*3, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.avg_pool2d(x, 2, 2)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.avg_pool2d(x, 2, 2)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.avg_pool2d(x, 2, 2)\n",
    "        x = self.bn3(x)\n",
    "        x = x.view(-1, 64*3*3)\n",
    "        x = self.drop(x)\n",
    "        x = self.fc1(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "def test(args, model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "args = {\n",
    "    'batch_size': 64,\n",
    "    'test_batch_size': 1000,\n",
    "    'epochs': 10,\n",
    "    'lr': 0.01,\n",
    "    'momentum': 0.5,\n",
    "    'no_cuda': False,\n",
    "    'seed': 1,\n",
    "    'log_interval': 100,\n",
    "    'save_model': False\n",
    "}\n",
    "args = namedtuple(\"args\", args.keys())(*args.values())\n",
    "\n",
    "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=args.test_batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "\n",
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n",
    "\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    train(args, model, device, train_loader, optimizer, epoch)\n",
    "    test(args, model, device, test_loader)\n",
    "\n",
    "if (args.save_model):\n",
    "    torch.save(model.state_dict(),\"mnist_cnn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 8, 8])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "from torch.nn.modules.utils import _pair\n",
    "from collections import namedtuple\n",
    "\n",
    "\n",
    "class SelfAttentionConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size,\n",
    "                 stride=1, padding=0, groups=4, bias=True):\n",
    "        super(SelfAttentionConv2d, self).__init__()\n",
    "        if in_channels % groups != 0:\n",
    "            raise ValueError('in_channels must be divisible by groups')\n",
    "        if out_channels % groups != 0:\n",
    "            raise ValueError('out_channels must be divisible by groups')\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = _pair(kernel_size)\n",
    "        self.stride = _pair(stride)\n",
    "        self.padding = _pair(padding)\n",
    "        self.groups = groups  # multi-head count\n",
    "        self.weight = namedtuple('fakeweight', ['shape'])([self.out_channels, self.in_channels])\n",
    "\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.Tensor(1, out_channels, 1, 1))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        # relative position offsets are shared between multi-heads\n",
    "        self.rel_size = (out_channels) // 2\n",
    "        print(self.rel_size)\n",
    "        print((out_channels) - self.rel_size)\n",
    "        self.relative_x = nn.Parameter(torch.Tensor(\n",
    "            self.rel_size, self.kernel_size[1]))\n",
    "        self.relative_y = nn.Parameter(torch.Tensor(\n",
    "            (out_channels) - self.rel_size, self.kernel_size[0]))\n",
    "\n",
    "        self.weight_query = nn.Conv2d(self.in_channels, self.out_channels,\n",
    "                                      1, groups=self.groups, bias=False)\n",
    "        self.weight_key = nn.Conv2d(self.in_channels, self.out_channels,\n",
    "                                    1, groups=self.groups, bias=False)\n",
    "        self.weight_value = nn.Conv2d(self.in_channels, self.out_channels,\n",
    "                                      1, groups=self.groups, bias=False)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=3)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        init.kaiming_normal_(self.weight_query.weight, mode='fan_out', nonlinearity='relu')\n",
    "        init.kaiming_normal_(self.weight_key.weight, mode='fan_out', nonlinearity='relu')\n",
    "        init.kaiming_normal_(self.weight_value.weight, mode='fan_out', nonlinearity='relu')\n",
    "\n",
    "        if self.bias is not None:\n",
    "            bound = 1 / math.sqrt(self.out_channels)\n",
    "            init.uniform_(self.bias, -bound, bound)\n",
    "\n",
    "        init.normal_(self.relative_x, 0, 1)\n",
    "        init.normal_(self.relative_y, 0, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.size()\n",
    "        kh, kw = self.kernel_size\n",
    "        ph, pw = h + self.padding[0] * 2, w + self.padding[1] * 2\n",
    "\n",
    "        fh = (ph - kh) // self.stride[0] + 1\n",
    "        fw = (pw - kw) // self.stride[1] + 1\n",
    "\n",
    "        px, py = self.padding\n",
    "        x = F.pad(x, (py, py, px, px))\n",
    "\n",
    "        vq = self.weight_query(x)\n",
    "        vk = self.weight_key(x)\n",
    "        vv = self.weight_value(x)  # b, fc, ph, pw\n",
    "\n",
    "        # b, fc, fh, fw\n",
    "        win_q = vq[:, :, (kh - 1) // 2:ph - (kh // 2):self.stride[0],\n",
    "                   (kw - 1) // 2:pw - (kw // 2):self.stride[1]]\n",
    "\n",
    "        win_q_b = win_q.view(b, -1, fh, fw)  # b, g, fc/g, fh, fw\n",
    "\n",
    "        # (b, g, x, fh, fw), (b, g, y, fh, fw)\n",
    "        win_q_x, win_q_y = win_q_b.split(self.rel_size, dim=1)\n",
    "        win_q_x = torch.einsum('bxhw,xk->bhwk', (win_q_x, self.relative_x))  # b, fh, fw, kw\n",
    "        win_q_y = torch.einsum('byhw,yk->bhwk', (win_q_y, self.relative_y))  # b, fh, fw, kh\n",
    "\n",
    "        win_k = vk.unfold(2, kh, self.stride[0]).unfold(\n",
    "            3, kw, self.stride[1])  # b, fc, fh, fw, kh, kw\n",
    "\n",
    "        vx = (win_q.unsqueeze(4).unsqueeze(4) * win_k).sum(dim=1)  # b, fh, fw, kh, kw\n",
    "        vx = vx + win_q_x.unsqueeze(3) + win_q_y.unsqueeze(4)  # add rel_x, rel_y\n",
    "        vx = self.softmax(vx.view(b, fh, fw, -1)).view(b, 1, fh, fw, kh, kw)\n",
    "\n",
    "        win_v = vv.unfold(2, kh, self.stride[0]).unfold(3, kw, self.stride[1])\n",
    "        # (b, fc, fh, fw, kh, kw) -> (b, fc, fh, fw)\n",
    "        fin_v = torch.einsum('bchwkl->bchw', (vx * win_v, ))\n",
    "\n",
    "        if self.bias is not None:\n",
    "            fin_v += self.bias\n",
    "\n",
    "        return fin_v\n",
    "\n",
    "# l = SelfAttentionConv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, groups=1)\n",
    "l = SelfAttentionConv2d(16, 32, 3, stride=1, padding=1, groups=4)\n",
    "x = torch.randn(3, 16, 8, 8)\n",
    "l(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Lib (RUN ME) - double-click to show/hide code\n",
    "####################\n",
    "## CORE\n",
    "#####################\n",
    "\n",
    "import inspect\n",
    "from collections import namedtuple, defaultdict\n",
    "from functools import partial\n",
    "import functools\n",
    "from itertools import chain, count, islice as take\n",
    "\n",
    "#####################\n",
    "## dict utils\n",
    "#####################\n",
    "\n",
    "union = lambda *dicts: {k: v for d in dicts for (k, v) in d.items()}\n",
    "\n",
    "make_tuple = lambda path: (path,) if isinstance(path, str) else path\n",
    "\n",
    "def path_iter(nested_dict, pfx=()):\n",
    "    for name, val in nested_dict.items():\n",
    "        if isinstance(val, dict): yield from path_iter(val, pfx+make_tuple(name))\n",
    "        else: yield (pfx+make_tuple(name), val)  \n",
    "            \n",
    "map_values = lambda func, dct: {k: func(v) for k,v in dct.items()}\n",
    "\n",
    "def map_nested(func, nested_dict):\n",
    "    return {k: map_nested(func, v) if isinstance(v, dict) else func(v) for k,v in nested_dict.items()}\n",
    "\n",
    "def group_by_key(seq):\n",
    "    res = defaultdict(list)\n",
    "    for k, v in seq: \n",
    "        res[k].append(v) \n",
    "    return res\n",
    "\n",
    "reorder = lambda dct, keys: {k: dct[k] for k in keys}\n",
    "\n",
    "#####################\n",
    "## graph building\n",
    "#####################\n",
    "\n",
    "def identity(value): return value\n",
    "\n",
    "def build_graph(net, path_map='_'.join):\n",
    "    net = {path: node if len(node) is 3 else (*node, None) for path, node in path_iter(net)}\n",
    "    default_inputs = chain([('input',)], net.keys())\n",
    "    resolve_path = lambda path, pfx: pfx+path if (pfx+path in net or not pfx) else resolve_path(net, path, pfx[:-1])\n",
    "    return {path_map(path): (typ, value, ([path_map(default)] if inputs is None else [path_map(resolve_path(make_tuple(k), path[:-1])) for k in inputs])) \n",
    "            for (path, (typ, value, inputs)), default in zip(net.items(), default_inputs)}\n",
    "\n",
    "#####################\n",
    "## network visualisation (requires pydot)\n",
    "#####################\n",
    "import IPython.display\n",
    "\n",
    "class ColorMap(dict):\n",
    "    palette = (\n",
    "        'bebada,ffffb3,fb8072,8dd3c7,80b1d3,fdb462,b3de69,fccde5,bc80bd,ccebc5,ffed6f,1f78b4,33a02c,e31a1c,ff7f00,'\n",
    "        '4dddf8,e66493,b07b87,4e90e3,dea05e,d0c281,f0e189,e9e8b1,e0eb71,bbd2a4,6ed641,57eb9c,3ca4d4,92d5e7,b15928'\n",
    "    ).split(',')\n",
    " \n",
    "    def __missing__(self, key):\n",
    "        self[key] = self.palette[len(self) % len(self.palette)]\n",
    "        return self[key]\n",
    "\n",
    "def make_pydot(nodes, edges, direction='LR', sep='_', **kwargs):\n",
    "    from pydot import Dot, Cluster, Node, Edge\n",
    "    class Subgraphs(dict):\n",
    "        def __missing__(self, path):\n",
    "            *parent, label = path\n",
    "            subgraph = Cluster(sep.join(path), label=label, style='rounded, filled', fillcolor='#77777744')\n",
    "            self[tuple(parent)].add_subgraph(subgraph)\n",
    "            return subgraph\n",
    "    g = Dot(rankdir=direction, directed=True, **kwargs)\n",
    "    g.set_node_defaults(\n",
    "        shape='box', style='rounded, filled', fillcolor='#ffffff')\n",
    "    subgraphs = Subgraphs({(): g})\n",
    "    for path, attr in nodes:\n",
    "        *parent, label = path.split(sep)\n",
    "        subgraphs[tuple(parent)].add_node(\n",
    "            Node(name=path, label=label, **attr))\n",
    "    for src, dst, attr in edges:\n",
    "        g.add_edge(Edge(src, dst, **attr))\n",
    "    return g\n",
    "\n",
    "class DotGraph():\n",
    "    colors = ColorMap()   \n",
    "    def __init__(self, graph, size=15, direction='LR'):\n",
    "        self.nodes = [(k, {\n",
    "            'tooltip': '%s %.1000r' % (typ, value), \n",
    "            'fillcolor': '#'+self.colors[typ],\n",
    "        }) for k, (typ, value, inputs) in graph.items()] \n",
    "        self.edges = [(src, k, {}) for (k, (_,_,inputs)) in graph.items() for src in inputs]\n",
    "        self.size, self.direction = size, direction\n",
    "\n",
    "    def dot_graph(self, **kwargs):\n",
    "        return make_pydot(self.nodes, self.edges, size=self.size, \n",
    "                            direction=self.direction, **kwargs)\n",
    "\n",
    "    def svg(self, **kwargs):\n",
    "        return self.dot_graph(**kwargs).create(format='svg').decode('utf-8')\n",
    "\n",
    "    try:\n",
    "        import pydot\n",
    "        def _repr_svg_(self):\n",
    "            return self.svg()\n",
    "    except ImportError:\n",
    "        def __repr__(self):\n",
    "            return 'pydot is needed for network visualisation'\n",
    "\n",
    "\n",
    "#####################\n",
    "## Layers\n",
    "##################### \n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from collections import namedtuple\n",
    "import copy\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "cpu = torch.device('cpu')\n",
    "    \n",
    "class Network(nn.Module):\n",
    "    def __init__(self, net, loss=None):\n",
    "        super().__init__()\n",
    "        self.graph = {path: (typ, typ(**params), inputs) for path, (typ, params, inputs) in build_graph(net).items()}\n",
    "        self.loss = loss or identity\n",
    "        for path, (_,node,_) in self.graph.items(): \n",
    "            setattr(self, path, node)\n",
    "    \n",
    "    def nodes(self):\n",
    "        return (node for _,node,_ in self.graph.values())\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        outputs = dict(inputs)\n",
    "        for k, (_, node, ins) in self.graph.items():\n",
    "            outputs[k] = node(*[outputs[x] for x in ins])\n",
    "        return outputs\n",
    "    \n",
    "    def half(self):\n",
    "        for node in self.nodes():\n",
    "            if isinstance(node, nn.Module) and not isinstance(node, nn.BatchNorm2d):\n",
    "                node.half()\n",
    "        return self\n",
    "\n",
    "build_model = lambda network, loss: Network(network, loss).half().to(device)\n",
    "show = lambda network, size=15: display(DotGraph(network.graph if isinstance(network, Network) else build_graph(network), size=size))\n",
    "    \n",
    "class Add(namedtuple('Add', [])):\n",
    "    def __call__(self, x, y): return x + y \n",
    "    \n",
    "class AddWeighted(namedtuple('AddWeighted', ['wx', 'wy'])):\n",
    "    def __call__(self, x, y): return self.wx*x + self.wy*y \n",
    "    \n",
    "class Identity(namedtuple('Identity', [])):\n",
    "    def __call__(self, x): return x\n",
    "\n",
    "class BatchNorm(nn.BatchNorm2d):\n",
    "    def __init__(self, num_features, eps=1e-05, momentum=0.1, weight=True, bias=True):\n",
    "        super().__init__(num_features, eps=eps, momentum=momentum)\n",
    "        self.weight.data.fill_(1.0)\n",
    "        self.bias.data.fill_(0.0)\n",
    "        self.weight.requires_grad = weight\n",
    "        self.bias.requires_grad = bias\n",
    "\n",
    "class GhostBatchNorm(BatchNorm):\n",
    "    def __init__(self, num_features, num_splits, **kw):\n",
    "        super().__init__(num_features, **kw)\n",
    "        self.num_splits = num_splits\n",
    "        self.register_buffer('running_mean', torch.zeros(num_features*self.num_splits))\n",
    "        self.register_buffer('running_var', torch.ones(num_features*self.num_splits))\n",
    "\n",
    "    def train(self, mode=True):\n",
    "        if (self.training is True) and (mode is False): #lazily collate stats when we are going to use them\n",
    "            self.running_mean = torch.mean(self.running_mean.view(self.num_splits, self.num_features), dim=0).repeat(self.num_splits)\n",
    "            self.running_var = torch.mean(self.running_var.view(self.num_splits, self.num_features), dim=0).repeat(self.num_splits)\n",
    "        return super().train(mode)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        N, C, H, W = input.shape\n",
    "        if self.training or not self.track_running_stats:\n",
    "            return F.batch_norm(\n",
    "                input.view(-1, C*self.num_splits, H, W), self.running_mean, self.running_var, \n",
    "                self.weight.repeat(self.num_splits), self.bias.repeat(self.num_splits),\n",
    "                True, self.momentum, self.eps).view(N, C, H, W) \n",
    "        else:\n",
    "            return F.batch_norm(\n",
    "                input, self.running_mean[:self.num_features], self.running_var[:self.num_features], \n",
    "                self.weight, self.bias, False, self.momentum, self.eps)\n",
    "        \n",
    "class Mul(nn.Module):\n",
    "    def __init__(self, weight):\n",
    "        super().__init__()\n",
    "        self.weight = weight\n",
    "    def __call__(self, x): \n",
    "        return x*self.weight\n",
    "    \n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x): \n",
    "        return x.view(x.size(0), x.size(1))\n",
    "\n",
    "# Losses\n",
    "class CrossEntropyLoss(namedtuple('CrossEntropyLoss', [])):\n",
    "    def __call__(self, log_probs, target):\n",
    "        return torch.nn.functional.nll_loss(log_probs, target, reduction='none')\n",
    "    \n",
    "class KLLoss(namedtuple('KLLoss', [])):        \n",
    "    def __call__(self, log_probs):\n",
    "        return -log_probs.mean(dim=1)\n",
    "\n",
    "class Correct(namedtuple('Correct', [])):\n",
    "    def __call__(self, classifier, target):\n",
    "        return classifier.max(dim = 1)[1] == target\n",
    "\n",
    "class LogSoftmax(namedtuple('LogSoftmax', ['dim'])):\n",
    "    def __call__(self, x):\n",
    "        return torch.nn.functional.log_softmax(x, self.dim, _stacklevel=5)\n",
    "\n",
    "    \n",
    "# node definitions   \n",
    "from inspect import signature    \n",
    "empty_signature = inspect.Signature()\n",
    "\n",
    "class node_def(namedtuple('node_def', ['type'])):\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return (self.type, dict(signature(self.type).bind(*args, **kwargs).arguments))\n",
    "\n",
    "# conv = node_def(nn.Conv2d)\n",
    "conv = node_def(SelfAttentionConv2d)\n",
    "linear = node_def(nn.Linear)\n",
    "batch_norm = node_def(BatchNorm)\n",
    "pool = node_def(nn.MaxPool2d)\n",
    "relu = node_def(nn.ReLU)\n",
    "    \n",
    "def map_types(mapping, net):\n",
    "    def f(node):\n",
    "        typ, *rest = node\n",
    "        return (mapping.get(typ, typ), *rest)\n",
    "    return map_nested(f, net) \n",
    "\n",
    "#####################\n",
    "## Compat\n",
    "##################### \n",
    "\n",
    "def to_numpy(x):\n",
    "    if isinstance(x, torch.Tensor):\n",
    "        return x.detach().cpu().numpy()  \n",
    "    return x\n",
    "  \n",
    "def flip_lr(x):\n",
    "    if isinstance(x, torch.Tensor):\n",
    "        return torch.flip(x, [-1]) \n",
    "    return x[..., ::-1].copy()\n",
    "  \n",
    "trainable_params = lambda model: {k:p for k,p in model.named_parameters() if p.requires_grad}\n",
    "\n",
    "#####################\n",
    "## Optimisers\n",
    "##################### \n",
    "\n",
    "from functools import partial\n",
    "\n",
    "def nesterov_update(w, dw, v, lr, weight_decay, momentum):\n",
    "    dw.add_(weight_decay, w).mul_(-lr)\n",
    "    v.mul_(momentum).add_(dw)\n",
    "    w.add_(dw.add_(momentum, v))\n",
    "\n",
    "norm = lambda x: torch.norm(x.reshape(x.size(0),-1).float(), dim=1)[:,None,None,None]\n",
    "\n",
    "def LARS_update(w, dw, v, lr, weight_decay, momentum):\n",
    "    nesterov_update(w, dw, v, lr*(norm(w)/(norm(dw)+1e-2)).to(w.dtype), weight_decay, momentum)\n",
    "\n",
    "def zeros_like(weights):\n",
    "    return [torch.zeros_like(w) for w in weights]\n",
    "\n",
    "def optimiser(weights, param_schedule, update, state_init):\n",
    "    weights = list(weights)\n",
    "    return {'update': update, 'param_schedule': param_schedule, 'step_number': 0, 'weights': weights,  'opt_state': state_init(weights)}\n",
    "\n",
    "def opt_step(update, param_schedule, step_number, weights, opt_state):\n",
    "    step_number += 1\n",
    "    param_values = {k: f(step_number) for k, f in param_schedule.items()}\n",
    "    for w, v in zip(weights, opt_state):\n",
    "        if w.requires_grad:\n",
    "            update(w.data, w.grad.data, v, **param_values)\n",
    "    return {'update': update, 'param_schedule': param_schedule, 'step_number': step_number, 'weights': weights,  'opt_state': opt_state}\n",
    "\n",
    "LARS = partial(optimiser, update=LARS_update, state_init=zeros_like)\n",
    "SGD = partial(optimiser, update=nesterov_update, state_init=zeros_like)\n",
    "  \n",
    "class PiecewiseLinear(namedtuple('PiecewiseLinear', ('knots', 'vals'))):\n",
    "    def __call__(self, t):\n",
    "        return np.interp([t], self.knots, self.vals)[0]\n",
    "     \n",
    "class Const(namedtuple('Const', ['val'])):\n",
    "    def __call__(self, x):\n",
    "        return self.val\n",
    "\n",
    "#####################\n",
    "## DATA\n",
    "##################### \n",
    "\n",
    "import torchvision\n",
    "from functools import lru_cache as cache\n",
    "\n",
    "@cache(None)\n",
    "def cifar10(root='./data'):\n",
    "    download = lambda train: torchvision.datasets.CIFAR10(root=root, train=train, download=True)\n",
    "    return {k: {'data': torch.tensor(v.data), 'targets': torch.tensor(v.targets)} \n",
    "            for k,v in [('train', download(True)), ('valid', download(False))]}\n",
    "  \n",
    "cifar10_mean, cifar10_std = [\n",
    "    (125.31, 122.95, 113.87), # equals np.mean(cifar10()['train']['data'], axis=(0,1,2)) \n",
    "    (62.99, 62.09, 66.70), # equals np.std(cifar10()['train']['data'], axis=(0,1,2))\n",
    "]\n",
    "cifar10_classes= 'airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck'.split(', ')\n",
    "\n",
    "#####################\n",
    "## data preprocessing\n",
    "#####################\n",
    "mean, std = [torch.tensor(x, device=device, dtype=torch.float16) for x in (cifar10_mean, cifar10_std)]\n",
    "\n",
    "normalise = lambda data, mean=mean, std=std: (data - mean)/std\n",
    "unnormalise = lambda data, mean=mean, std=std: data*std + mean\n",
    "pad = lambda data, border: nn.ReflectionPad2d(border)(data)\n",
    "transpose = lambda x, source='NHWC', target='NCHW': x.permute([source.index(d) for d in target]) \n",
    "to = lambda *args, **kwargs: (lambda x: x.to(*args, **kwargs))\n",
    "\n",
    "def preprocess(dataset, transforms):\n",
    "    dataset = copy.copy(dataset)\n",
    "    for transform in reversed(transforms):\n",
    "        dataset['data'] = transform(dataset['data'])\n",
    "    return dataset\n",
    "\n",
    "#####################\n",
    "## Data augmentation\n",
    "#####################\n",
    "\n",
    "chunks = lambda data, splits: (data[start:end] for (start, end) in zip(splits, splits[1:]))\n",
    "\n",
    "even_splits = lambda N, num_chunks: np.cumsum([0] + [(N//num_chunks)+1]*(N % num_chunks)  + [N//num_chunks]*(num_chunks - (N % num_chunks)))\n",
    "\n",
    "def shuffled(xs, inplace=False):\n",
    "    xs = xs if inplace else copy.copy(xs) \n",
    "    np.random.shuffle(xs)\n",
    "    return xs\n",
    "\n",
    "def transformed(data, targets, transform, max_options=None, unshuffle=False):\n",
    "    i = torch.randperm(len(data), device=device)\n",
    "    data = data[i]\n",
    "    options = shuffled(transform.options(data.shape), inplace=True)[:max_options]\n",
    "    data = torch.cat([transform.apply(x, **choice) for choice, x in zip(options, chunks(data, even_splits(len(data), len(options))))])\n",
    "    return (data[torch.argsort(i)], targets) if unshuffle else (data, targets[i])\n",
    "\n",
    "class Batches():\n",
    "    def __init__(self, batch_size, transforms=(), dataset=None, shuffle=True, drop_last=False, max_options=None):\n",
    "        self.dataset, self.transforms, self.shuffle, self.max_options = dataset, transforms, shuffle, max_options\n",
    "        N = len(dataset['data'])\n",
    "        self.splits = list(range(0, N+1, batch_size))\n",
    "        if not drop_last and self.splits[-1] != N:\n",
    "            self.splits.append(N)\n",
    "     \n",
    "    def __iter__(self):\n",
    "        data, targets = self.dataset['data'], self.dataset['targets']\n",
    "        for transform in self.transforms:\n",
    "            data, targets = transformed(data, targets, transform, max_options=self.max_options, unshuffle=not self.shuffle)\n",
    "        if self.shuffle:\n",
    "            i = torch.randperm(len(data), device=device)\n",
    "            data, targets = data[i], targets[i]\n",
    "        return ({'input': x.clone(), 'target': y} for (x, y) in zip(chunks(data, self.splits), chunks(targets, self.splits)))\n",
    "    \n",
    "    def __len__(self): \n",
    "        return len(self.splits) - 1\n",
    "    \n",
    "#####################\n",
    "## Augmentations\n",
    "#####################\n",
    "\n",
    "class Crop(namedtuple('Crop', ('h', 'w'))):\n",
    "    def apply(self, x, x0, y0):\n",
    "        return x[..., y0:y0+self.h, x0:x0+self.w] \n",
    "\n",
    "    def options(self, shape):\n",
    "        *_, H, W = shape\n",
    "        return [{'x0': x0, 'y0': y0} for x0 in range(W+1-self.w) for y0 in range(H+1-self.h)]\n",
    "    \n",
    "class FlipLR(namedtuple('FlipLR', ())):\n",
    "    def apply(self, x, choice):\n",
    "        return flip_lr(x) if choice else x \n",
    "        \n",
    "    def options(self, shape):\n",
    "        return [{'choice': b} for b in [True, False]]\n",
    "\n",
    "class Cutout(namedtuple('Cutout', ('h', 'w'))):\n",
    "    def apply(self, x, x0, y0):\n",
    "        x[..., y0:y0+self.h, x0:x0+self.w] = 0.0\n",
    "        return x\n",
    "\n",
    "    def options(self, shape):\n",
    "        *_, H, W = shape\n",
    "        return [{'x0': x0, 'y0': y0} for x0 in range(W+1-self.w) for y0 in range(H+1-self.h)]  \n",
    "\n",
    "#####################\n",
    "## TRAINING\n",
    "#####################\n",
    "\n",
    "import time\n",
    "\n",
    "class Timer():\n",
    "    def __init__(self, synch=None):\n",
    "        self.synch = synch or (lambda: None)\n",
    "        self.synch()\n",
    "        self.times = [time.perf_counter()]\n",
    "        self.total_time = 0.0\n",
    "\n",
    "    def __call__(self, update_total=True):\n",
    "        self.synch()\n",
    "        self.times.append(time.perf_counter())\n",
    "        delta_t = self.times[-1] - self.times[-2]\n",
    "        if update_total:\n",
    "            self.total_time += delta_t\n",
    "        return delta_t\n",
    "\n",
    "default_table_formats = {float: '{:{w}.4f}', str: '{:>{w}s}', 'default': '{:{w}}', 'title': '{:>{w}s}'}\n",
    "\n",
    "def table_formatter(val, is_title=False, col_width=12, formats=None):\n",
    "    formats = formats or default_table_formats\n",
    "    type_ = lambda val: float if isinstance(val, (float, np.float)) else type(val)\n",
    "    return (formats['title'] if is_title else formats.get(type_(val), formats['default'])).format(val, w=col_width)\n",
    "\n",
    "every = lambda n, col: (lambda data: data[col] % n == 0)\n",
    "\n",
    "class Table():\n",
    "    def __init__(self, keys=None, report=(lambda data: True), formatter=table_formatter):\n",
    "        self.keys, self.report, self.formatter = keys, report, formatter\n",
    "        self.log = []\n",
    "        \n",
    "    def append(self, data):\n",
    "        self.log.append(data)\n",
    "        data = {' '.join(p): v for p,v in path_iter(data)}\n",
    "        self.keys = self.keys or data.keys()\n",
    "        if len(self.log) is 1:\n",
    "            print(*(self.formatter(k, True) for k in self.keys))\n",
    "        if self.report(data):\n",
    "            print(*(self.formatter(data[k]) for k in self.keys))\n",
    "            \n",
    "    def df(self):\n",
    "        return pd.DataFrame([{'_'.join(p): v for p,v in path_iter(row)} for row in self.log])     \n",
    "            \n",
    "def reduce(batches, state, steps):\n",
    "    #state: is a dictionary\n",
    "    #steps: are functions that take (batch, state)\n",
    "    #and return a dictionary of updates to the state (or None)\n",
    "    \n",
    "    for batch in chain(batches, [None]): \n",
    "    #we send an extra batch=None at the end for steps that \n",
    "    #need to do some tidying-up (e.g. log_activations)\n",
    "        for step in steps:\n",
    "            updates = step(batch, state)\n",
    "            if updates:\n",
    "                for k,v in updates.items():\n",
    "                    state[k] = v                  \n",
    "    return state\n",
    "  \n",
    "#define keys in the state dict as constants\n",
    "MODEL = 'model'\n",
    "VALID_MODEL = 'valid_model'\n",
    "OUTPUT = 'output'\n",
    "OPTS = 'optimisers'\n",
    "ACT_LOG = 'activation_log'\n",
    "WEIGHT_LOG = 'weight_log'\n",
    "\n",
    "#step definitions\n",
    "def forward(training_mode):\n",
    "    def step(batch, state):\n",
    "        if not batch: return\n",
    "        model = state[MODEL] if training_mode or (VALID_MODEL not in state) else state[VALID_MODEL]\n",
    "        if model.training != training_mode: #without the guard it's slow!\n",
    "            model.train(training_mode)\n",
    "        return {OUTPUT: model.loss(model(batch))}\n",
    "    return step\n",
    "\n",
    "def forward_tta(tta_transforms):\n",
    "    def step(batch, state):\n",
    "        if not batch: return\n",
    "        model = state[MODEL] if (VALID_MODEL not in state) else state[VALID_MODEL]\n",
    "        if model.training:\n",
    "            model.train(False)\n",
    "        logits = torch.mean(torch.stack([model({'input': transform(batch['input'].clone())})['logits'].detach() for transform in tta_transforms], dim=0), dim=0)\n",
    "        return {OUTPUT: model.loss(dict(batch, logits=logits))}\n",
    "    return step\n",
    "\n",
    "def backward(dtype=torch.float16):\n",
    "    def step(batch, state):\n",
    "        state[MODEL].zero_grad()\n",
    "        if not batch: return\n",
    "        state[OUTPUT]['loss'].to(dtype).sum().backward()\n",
    "    return step\n",
    "\n",
    "def opt_steps(batch, state):\n",
    "    if not batch: return\n",
    "    return {OPTS: [opt_step(**opt) for opt in state[OPTS]]}\n",
    "\n",
    "def log_activations(node_names=('loss', 'acc')):\n",
    "    logs = []\n",
    "    def step(batch, state):\n",
    "        if batch:\n",
    "            logs.extend((k, state[OUTPUT][k].detach()) for k in node_names)\n",
    "        else:\n",
    "            res = map_values((lambda xs: to_numpy(torch.cat(xs)).astype(np.float)), group_by_key(logs))\n",
    "            logs.clear()\n",
    "            return {ACT_LOG: res}\n",
    "    return step\n",
    "\n",
    "def update_ema(momentum, update_freq=1):\n",
    "    n = iter(count())\n",
    "    rho = momentum**update_freq\n",
    "    def step(batch, state):\n",
    "        if not batch: return\n",
    "        if (next(n) % update_freq) != 0: return\n",
    "        for v, ema_v in zip(state[MODEL].state_dict().values(), state[VALID_MODEL].state_dict().values()):\n",
    "            ema_v *= rho\n",
    "            ema_v += (1-rho)*v\n",
    "    return step\n",
    "\n",
    "train_steps = (forward(training_mode=True), log_activations(('loss', 'acc')), backward(), opt_steps)\n",
    "valid_steps = (forward(training_mode=False), log_activations(('loss', 'acc')))\n",
    "\n",
    "epoch_stats = lambda state: {k: np.mean(v) for k, v in state[ACT_LOG].items()}\n",
    "\n",
    "def train_epoch(state, timer, train_batches, valid_batches, train_steps=train_steps, valid_steps=valid_steps, on_epoch_end=identity):\n",
    "    train_summary, train_time = epoch_stats(on_epoch_end(reduce(train_batches, state, train_steps))), timer()\n",
    "    valid_summary, valid_time = epoch_stats(reduce(valid_batches, state, valid_steps)), timer(update_total=False) #DAWNBench rules\n",
    "    return {\n",
    "        'train': union({'time': train_time}, train_summary), \n",
    "        'valid': union({'time': valid_time}, valid_summary), \n",
    "        'total time': timer.total_time\n",
    "    }\n",
    "\n",
    "summary = lambda logs, cols=['valid_acc']: logs.df().query('epoch==epoch.max()')[cols].describe().transpose().astype({'count': int})[\n",
    "    ['count', 'mean', 'min', 'max', 'std']]\n",
    "\n",
    "#on_epoch_end\n",
    "def log_weights(state, weights):\n",
    "    state[WEIGHT_LOG] = state.get(WEIGHT_LOG, [])\n",
    "    state[WEIGHT_LOG].append({k: to_numpy(v.data) for k,v in weights.items()})\n",
    "    return state\n",
    "\n",
    "def fine_tune_bn_stats(state, batches, model_key=VALID_MODEL):\n",
    "    reduce(batches, {MODEL: state[model_key]}, [forward(True)])\n",
    "    return state\n",
    "\n",
    "#misc\n",
    "def warmup_cudnn(model, batch):\n",
    "    #run forward and backward pass of the model\n",
    "    #to allow benchmarking of cudnn kernels \n",
    "    reduce([batch], {MODEL: model}, [forward(True), backward()])\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "\n",
    "#####################\n",
    "## Plotting\n",
    "#####################\n",
    "\n",
    "import altair as alt\n",
    "alt.renderers.enable('colab')\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import SVG\n",
    "\n",
    "def empty_plot(ax, **kw):\n",
    "    ax.axis('off')\n",
    "    return ax\n",
    "\n",
    "def image_plot(ax, img, title):\n",
    "    ax.imshow(to_numpy(unnormalise(transpose(img, 'CHW', 'HWC'))).astype(np.int))\n",
    "    ax.set_title(title)\n",
    "    ax.axis('off')\n",
    "\n",
    "def layout(figures, sharex=False, sharey=False, figure_title=None, col_width=4, row_height = 3.25, **kw):\n",
    "    nrows, ncols = np.array(figures).shape\n",
    "\n",
    "    fig, axs = plt.subplots(nrows=nrows, ncols=ncols, sharex=sharex, sharey=sharey, figsize=(col_width*ncols, row_height*nrows))\n",
    "    axs = [figure(ax, **kw) for row in zip(np.array(axs).reshape(nrows, ncols), figures) for ax, figure in zip(*row)]\n",
    "    fig.suptitle(figure_title)\n",
    "    return fig, axs\n",
    "\n",
    "#####################\n",
    "## Network\n",
    "#####################\n",
    "\n",
    "conv_block = lambda c_in, c_out: {\n",
    "    'conv': conv(in_channels=c_in, out_channels=c_out, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), \n",
    "    'norm': batch_norm(c_out), \n",
    "    'act':  relu(),\n",
    "}\n",
    "\n",
    "conv_pool_block = lambda c_in, c_out: dict(conv_block(c_in, c_out), pool=pool(2))\n",
    "conv_pool_block_pre = lambda c_in, c_out: reorder(conv_pool_block(c_in, c_out), ('conv', 'pool', 'norm', 'act'))\n",
    "\n",
    "residual = lambda c, conv_block: {\n",
    "    'in': (Identity, {}),\n",
    "    'res1': conv_block(c, c),\n",
    "    'res2': conv_block(c, c),\n",
    "    'out': (Identity, {}),\n",
    "    'add': (Add, {}, ['in', 'out']),\n",
    "}\n",
    "\n",
    "def build_network(channels, extra_layers, res_layers, scale, conv_block=conv_block, \n",
    "                  prep_block=conv_block, conv_pool_block=conv_pool_block, types=None): \n",
    "    net = {\n",
    "        'prep': prep_block(3, channels['prep']),\n",
    "        'layer1': conv_pool_block(channels['prep'], channels['layer1']),\n",
    "        'layer2': conv_pool_block(channels['layer1'], channels['layer2']),\n",
    "        'layer3': conv_pool_block(channels['layer2'], channels['layer3']),\n",
    "        'pool': pool(4),\n",
    "        'classifier': {\n",
    "            'flatten': (Flatten, {}),\n",
    "            'conv': linear(channels['layer3'], 10, bias=False),\n",
    "            'scale': (Mul, {'weight': scale}),\n",
    "        },\n",
    "        'logits': (Identity, {}),\n",
    "    }\n",
    "    for layer in res_layers:\n",
    "        net[layer]['residual'] = residual(channels[layer], conv_block)\n",
    "    for layer in extra_layers:\n",
    "        net[layer]['extra'] = conv_block(channels[layer], channels[layer])     \n",
    "    if types: net = map_types(types, net)\n",
    "    return net\n",
    "\n",
    "channels={'prep': 64, 'layer1': 128, 'layer2': 256, 'layer3': 512}\n",
    "network = partial(build_network, channels=channels, extra_layers=(), res_layers=('layer1', 'layer3'), scale=1/8)   \n",
    "\n",
    "x_ent_loss = Network({\n",
    "  'loss':  (nn.CrossEntropyLoss, {'reduction': 'none'}, ['logits', 'target']),\n",
    "  'acc': (Correct, {}, ['logits', 'target'])\n",
    "})\n",
    "\n",
    "label_smoothing_loss = lambda alpha: Network({\n",
    "        'logprobs': (LogSoftmax, {'dim': 1}, ['logits']),\n",
    "        'KL':  (KLLoss, {}, ['logprobs']),\n",
    "        'xent':  (CrossEntropyLoss, {}, ['logprobs', 'target']),\n",
    "        'loss': (AddWeighted, {'wx': 1-alpha, 'wy': alpha}, ['xent', 'KL']),\n",
    "        'acc': (Correct, {}, ['logits', 'target']),\n",
    "    })\n",
    "\n",
    "#####################\n",
    "## Misc\n",
    "#####################\n",
    "\n",
    "lr_schedule = lambda knots, vals, batch_size: PiecewiseLinear(np.array(knots)*len(train_batches(batch_size)), np.array(vals)/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Starting timer\n",
      "Transfer to GPU:\t0.072s\n",
      "Data preprocessing:\t0.026s\n",
      "Transfer to CPU:\t0.345s\n"
     ]
    }
   ],
   "source": [
    "#####################\n",
    "## timings\n",
    "#####################\n",
    "dataset = cifar10() #downloads dataset\n",
    "print('Starting timer')\n",
    "t = Timer(synch=torch.cuda.synchronize)\n",
    "dataset = map_nested(to(device), dataset)\n",
    "print(f'Transfer to GPU:\\t{t():.3f}s')\n",
    "train_set = preprocess(dataset['train'], [partial(pad, border=4), transpose, normalise, to(torch.float16)])\n",
    "valid_set = preprocess(dataset['valid'], [transpose, normalise, to(torch.float16)])\n",
    "print(f'Data preprocessing:\\t{t():.3f}s')\n",
    "map_nested(to(cpu), {'train': train_set, 'valid': valid_set})\n",
    "print(f'Transfer to CPU:\\t{t():.3f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches = partial(Batches, dataset=train_set, shuffle=True,  drop_last=True, max_options=200)\n",
    "valid_batches = partial(Batches, dataset=valid_set, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batches = train_batches(batch_size=8, transforms=(Crop(32, 32), FlipLR(), Cutout(8, 8)), shuffle=False)\n",
    "\n",
    "# layout([[partial(image_plot, img=x, title=cifar10_classes[y]) for x,y in zip(*next(iter(batches)).values())]], col_width=2, row_height=2)\n",
    "# layout([[partial(image_plot, img=x, title=cifar10_classes[y]) for x,y in zip(*next(iter(batches)).values())]], col_width=2, row_height=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Timer(synch=torch.cuda.synchronize)\n",
    "batches = train_batches(batch_size=512, transforms=(Crop(32, 32), FlipLR(), Cutout(8, 8)))\n",
    "\n",
    "# for epoch in range(24):\n",
    "#     for batch in batches:\n",
    "#         pass\n",
    "# print(f'{t():.3f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pydot is needed for network visualisation"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "baseline_net=network()\n",
    "show(baseline_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "32\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "128\n",
      "128\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 4.50 GiB (GPU 0; 10.92 GiB total capacity; 5.38 GiB already allocated; 3.48 GiB free; 1.44 GiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-a67495342140>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbaseline_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_ent_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mwarmup_cudnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mMODEL\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOPTS\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainable_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msynchronize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-c991aedd3fcc>\u001b[0m in \u001b[0;36mwarmup_cudnn\u001b[0;34m(model, batch)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;31m#run forward and backward pass of the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[0;31m#to allow benchmarking of cudnn kernels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m     \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mMODEL\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msynchronize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-c991aedd3fcc>\u001b[0m in \u001b[0;36mreduce\u001b[0;34m(batches, state, steps)\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m#need to do some tidying-up (e.g. log_activations)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m             \u001b[0mupdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mupdates\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mupdates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-c991aedd3fcc>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(batch, state)\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mMODEL\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m         \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOUTPUT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/p36/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/p36/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 4.50 GiB (GPU 0; 10.92 GiB total capacity; 5.38 GiB already allocated; 3.48 GiB free; 1.44 GiB cached)"
     ]
    }
   ],
   "source": [
    "epochs, batch_size = 24, 512\n",
    "transforms = (Crop(32, 32), FlipLR(), Cutout(8, 8))\n",
    "opt_params = {'lr': lr_schedule([0, 5, epochs], [0.0, 0.4, 0.0], batch_size), 'weight_decay': Const(5e-4*batch_size), 'momentum': Const(0.9)}\n",
    "\n",
    "model = build_model(baseline_net, x_ent_loss)  \n",
    "warmup_cudnn(model, next(iter(train_batches(batch_size, transforms))))\n",
    "logs, state, timer = Table(), {MODEL: model, OPTS: [SGD(trainable_params(model).values(), opt_params)]}, Timer(torch.cuda.synchronize)\n",
    "for epoch in range(epochs):\n",
    "    logs.append(union({'epoch': epoch+1}, train_epoch(state, timer, train_batches(batch_size, transforms), valid_batches(batch_size))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       epoch   train time   train loss    train acc   valid time   valid loss    valid acc   total time\n",
      "           1       8.6170       1.6447       0.4084       0.9453       1.2173       0.5464       8.6170\n",
      "           2       8.6378       0.9551       0.6590       0.5448       0.8977       0.6963      17.2548\n",
      "           3       8.6384       0.7367       0.7407       0.5468       0.6215       0.7845      25.8932\n",
      "           4       8.6563       0.6254       0.7826       0.5456       0.7033       0.7602      34.5494\n",
      "           5       8.6655       0.5611       0.8066       0.5472       0.6971       0.7669      43.2149\n",
      "           6       8.6796       0.4990       0.8281       0.5473       0.5102       0.8286      51.8946\n",
      "           7       8.6701       0.4504       0.8469       0.5478       0.6228       0.7816      60.5646\n",
      "           8       8.6845       0.4114       0.8598       0.5474       0.5754       0.8010      69.2491\n"
     ]
    }
   ],
   "source": [
    "epochs, batch_size = 24, 512\n",
    "transforms = (Crop(32, 32), FlipLR(), Cutout(8, 8))\n",
    "opt_params = {'lr': lr_schedule([0, 5, epochs], [0.0, 0.4, 0.0], batch_size), 'weight_decay': Const(5e-4*batch_size), 'momentum': Const(0.9)}\n",
    "\n",
    "model = build_model(baseline_net, x_ent_loss)  \n",
    "warmup_cudnn(model, next(iter(train_batches(batch_size, transforms))))\n",
    "logs, state, timer = Table(), {MODEL: model, OPTS: [SGD(trainable_params(model).values(), opt_params)]}, Timer(torch.cuda.synchronize)\n",
    "for epoch in range(epochs):\n",
    "    logs.append(union({'epoch': epoch+1}, train_epoch(state, timer, train_batches(batch_size, transforms), valid_batches(batch_size))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p36'\n'",
   "language": "python",
   "name": "p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
